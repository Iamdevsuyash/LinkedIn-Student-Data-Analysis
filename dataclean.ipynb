{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".DS_Store\n",
      "file processed :  Aaditya_Raj - Aaditya Raj.csv\n",
      "file processed :  Abhishek_Singh - Abhishek Singh.csv\n",
      "file processed :  Aditya_Singh - Aditya NO-LASTNAME.csv\n",
      "file processed :  Afzal_Raza - Afzl Raza.csv\n",
      "file processed :  Ajay Jatav Connections-1 - Ajay Jatav.csv\n",
      "file processed :  Ajit_Yadav - Ajit Yadav.csv\n",
      "file processed :  Akanksha_Kushwaha - Akanksha.csv\n",
      "file processed :  Alok_raj - Alok Raj.csv\n",
      "file processed :  Aman_ Adarsh.csv\n",
      "file processed :  Aman_Singh - Aman Singh.csv\n",
      "file processed :  amit_kumar - Amit Kumar.csv\n",
      "file processed :  Anamika_Kumari - Anamika Kumari.csv\n",
      "file processed :  Anand_Pandey - Anand Pandey.csv\n",
      "file processed :  Anoop_Kumar - ANOOP KUMAR.csv\n",
      "file processed :  Anshu_Kumar - Anshu Kumar.csv\n",
      "file processed :  Anuradha_Tiwari - Anuradha Tiwari.csv\n",
      "file processed :  Anushri_Mishra - Anushri Mishra.csv\n",
      "file processed :  Aradhya_Patel - Aradhya Patel.csv\n",
      "file processed :  Arjun Kadam - Arjun Kadam.csv\n",
      "file processed :  Arpita_Tripathi - Arpita Tripathi.csv\n",
      "file processed :  Arun_Singh - ARUN KUMAR.csv\n",
      "file processed :  aryan_saini - Aryan Saini.csv\n",
      "file processed :  Ashwin_Yadav - Ashwin Yadav.csv\n",
      "file processed :  Ayush_Kumar - Ayush Kumar.csv\n",
      "file processed :  Ayush_yadav - AYUSH YADAV.csv\n",
      "file processed :  Bhagwati_Chouhan - Bhagwati NO-LASTNAME.csv\n",
      "file processed :  Bhaskar_mahato - Bhaskar Mahato.csv\n",
      "file processed :  ByagariPraveen_Kumar - Byagari Kumar.csv\n",
      "file processed :  Challa_Trivedh_Kumar - CHALLA TRIVEDH KUMAR.csv\n",
      "file processed :  CHANDAN_GIRI - Chandan Giri.csv\n",
      "file processed :  Chiranjeet_Biswas - Chiranjeet Biswas.csv\n",
      "file processed :  Cleaned_Connections - Bhagwan Singh Rawat.csv\n",
      "file processed :  Connection - VISHAL KUMAR.csv\n",
      "file processed :  connection1-1 - Aman Adarsh.csv\n",
      "file processed :  Connections - Aman Verma.csv\n",
      "file processed :  Connections - Anand Singh.csv\n",
      "file processed :  Connections - Harshit Chaturvedi.csv\n",
      "file processed :  connections - N. Arun Kumar.csv\n",
      "file processed :  Connections - Ompal Yadav.csv\n",
      "file processed :  debangsu_misra.csv - Debangsu Misra.csv\n",
      "file processed :  Dilip_Suthar - DILIP SUTHAR.csv\n",
      "file processed :  Disha_Sahu - Disha Sahu.csv\n",
      "file processed :  Divyanshi_Rathour - Divyanshi Rathour.csv\n",
      "file processed :  Divyanshi_Sahu.csv - Divyanshi Sahu.csv\n",
      "file processed :  Ekta Kumari - Ekta Kumari.csv\n",
      "file processed :  gaurav_khainwar.csv - Gaurav Khainwar.csv\n",
      "file processed :  Gaurav_Rathore - Gaurav Rathore.csv\n",
      "file processed :  Gaurav_Tiwari - GAURAV TIWARI.csv\n",
      "file processed :  Harisingh_Rajpoot - Harisingh Rajpoot.csv\n",
      "file processed :  HimanshuKanwarChundawat - Himanshu Chundawat.csv\n",
      "file processed :  Himanshu_kumar - Himanshu Kumar.csv\n",
      "file processed :  Himanshu_Srivastav - Himanshu Srivastav.csv\n",
      "file processed :  Hiranya_Patil - Hiranya Patil.csv\n",
      "file processed :  Ishant_Bhoyar - ISHANT BHOYAR.csv\n",
      "file processed :  JAMAL_AKHTAR - JAMAL AKHTAR.csv\n",
      "file processed :  Janu_Chaudhary - Janu Chaudhary.csv\n",
      "file processed :  KARANPAL_SINGH_RANAWAT - KARANPAL SINGH RANAWAT.csv\n",
      "file processed :  khushi_narwariya - Khushi Narwariya.csv\n",
      "file processed :  Kuldeep_Saraswat - Kuldeep saraswat.csv\n",
      "file processed :  Lakhan_Rathore - Lakhan Rathore.csv\n",
      "file processed :  linkedin list - Nidhi Kumari.csv\n",
      "file processed :  linkedin_Connections - SNEHA SHAW.csv\n",
      "file processed :  Linked_in_connection - Samina Sultana.csv\n",
      "file processed :  Maneesh_Sakhwar - Maneesh Sakhwar.csv\n",
      "file processed :  Manish_Tiwari - MANISH KUMAR TIWARI.csv\n",
      "file processed :  Manoj K. Connections - MANOJ KHARKAR.csv\n",
      "file processed :  Manoj_Dewda - Manoj Dewda.csv\n",
      "file processed :  Mausam_kumari - Mausam kumari.csv\n",
      "file processed :  Mayank_Raj - Mayank Raj.csv\n",
      "file processed :  Mehtab_Alam - MEHTAB ALAM.csv\n",
      "file processed :  Mohd_Monis - Monis.csv\n",
      "file processed :  Mohit_Sharma - Mohit Sharma.csv\n",
      "file processed :  Monu_Rajpoot - Monu Rajpoot.csv\n",
      "file processed :  Naman_Damami - Naman Damami.csv\n",
      "file processed :  Neeraj_Parmar - NEERAJ PARMAR.csv\n",
      "file processed :  Nikhil_Chaurasiya - Nikhil Chaurasiya.csv\n",
      "file processed :  Nirmal LinkdIn Connections - NIRMAL MEWADA.csv\n",
      "file processed :  Pawan_Kushwah - Pawan Kushwah.csv\n",
      "file processed :  Pinky_Rana - Pinky Rana.csv\n",
      "file processed :  Pooran_Singh -  Pooran Singh.csv\n",
      "file processed :  Prabhat_Patidar - prabhat patidar.csv\n",
      "file processed :  Prachi_Dhakad - PRACHI DHAKAD.csv\n",
      "file processed :  Pragati_Chauhan - Pragati Chauhan.csv\n",
      "file processed :  Pranjal_Dubey - Pranjal Dubey.csv\n",
      "file processed :  Prem kumar.csv\n",
      "file processed :  Prerana_Rajnag - PRERANA RAJNAG.csv\n",
      "file processed :  Priyadarshi_Kumar - Priyadarshi Kumar.csv\n",
      "file processed :  Priya_saini - Priya Saini.csv\n",
      "file processed :  Pushpraj_Singh.csv - Pushpraj Singh.csv\n",
      "file processed :  Rahul_Kumar - Rahul Kumar.csv\n",
      "file processed :  Rahul_Kumar_Verma - Rahul Verma.csv\n",
      "file processed :  Rajiv_Kumar - RAJIV KUMAR.csv\n",
      "file processed :  Ramraj_Nagar - Ramraj Nagar.csv\n",
      "file processed :  Rani_Kumari - Rani Kumari.csv\n",
      "file processed :  Ranjeet_Kumar_Yadav - Ranjeet Yadav.csv\n",
      "file processed :  Ravi_Mourya - Ravi Mourya.csv\n",
      "file processed :  Ravi_Rajput - RAVI RAJPUT.csv\n",
      "file processed :  Ritik_Singh - ritik singh.csv\n",
      "file processed :  Rohit_kumar - ROHIT KUMAR.csv\n",
      "file processed :  Rohit_Malviya - Rohit Malviya.csv\n",
      "file processed :  Sajan_Kumar - SAJAN KUMAR.csv\n",
      "file processed :  Sandeep_kumar - Sandeep Kumar.csv\n",
      "file processed :  Sandhya_Kaushal - Sandhya Kaushal.csv\n",
      "file processed :  Sandhya_Parmar - Sandhya Parmar.csv\n",
      "file processed :  Sarthaksuman_Mishra - Sarthak Mishra.csv\n",
      "file processed :  Satish_Mahto - Satish Mahto.csv\n",
      "file processed :  Sauhard_kumar - Sauhard kumar.csv\n",
      "file processed :  Saurabh_Bisht - Saurabh Bisht.csv\n",
      "file processed :  Shahid_Ansari - Shahid Ansari.csv\n",
      "file processed :  Shilpi_Shaw - Shilpi Shaw.csv\n",
      "file processed :  Shivam_Shukla.csv\n",
      "file processed :  Shivang_Dubey - Shivang Dubey.csv\n",
      "file processed :  Shlok_Gupta - Shlok Gupta.csv\n",
      "file processed :  Shubham Kumar - Shubham Kumar.csv\n",
      "file processed :  Shubham_Kang - Shubham Kang.csv\n",
      "file processed :  Sunny_Kumar - Sunny Kumar.csv\n",
      "file processed :  Suyash_Yadav - Suyash Yadav.csv\n",
      "file processed :  Swati_Kumari - Swati kumari.csv\n",
      "file processed :  Ujjval_Baijal - Ujjval Baijal.csv\n",
      "file processed :  Uppara Sai_Maithreyi - UPPARA MAITHREYI.csv\n",
      "file processed :  Vinay_Gupta - VINAY GUPTA.csv\n",
      "file processed :  Vinay_Kumar - VINAY KUMAR.csv\n",
      "file processed :  Vishal_Bhardwaj - VISHAL BHARDWAJ.csv\n",
      "file processed :  Vivek_kumar - VIVEK KUMAR.csv\n",
      "file processed :  Vivek_Singh - Vivek Kumar.csv\n",
      "file processed :  YuvrajSingh_Bhati - Yuvraj Bhati.csv\n",
      "file processed :  Yuvraj_Chirag - Yuvraj Chirag.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import chardet\n",
    "\n",
    "# Detect encoding for CSV files\n",
    "def detect_encoding(file_path):\n",
    "    with open(file_path, 'rb') as f:\n",
    "        result = chardet.detect(f.read(10000))  # First 10KB is usually enough\n",
    "        return result['encoding']\n",
    "    \n",
    "\n",
    "# Find the header row containing expected columns\n",
    "def find_header_row(filepath, is_excel=False, encoding='utf-8'):\n",
    "    rows_to_check = 10\n",
    "    if is_excel:\n",
    "        preview = pd.read_excel(filepath, header=None, nrows=rows_to_check, engine='openpyxl')\n",
    "    else:\n",
    "        preview = pd.read_csv(filepath, header=None, nrows=rows_to_check, encoding=encoding)\n",
    "\n",
    "    for i in range(rows_to_check):\n",
    "        row = preview.iloc[i].astype(str).str.lower()\n",
    "        if {'First name', 'Last name', 'Company'}.issubset(set(row)):\n",
    "            return i\n",
    "    return 0  # fallback if not found\n",
    "\n",
    "\n",
    "directory = r'LinkedIn Data Public'\n",
    "files = os.listdir(directory)\n",
    "\n",
    "for file in files:\n",
    "    file_path = os.path.join(directory, file)\n",
    "\n",
    "    try:\n",
    "        # Process Excel files\n",
    "        if file.endswith('.xlsx'):\n",
    "            header_row = find_header_row(file_path, is_excel=True)\n",
    "            df = pd.read_excel(file_path, engine='openpyxl', header=header_row)\n",
    "\n",
    "            df = df[['First Name', 'Last Name', 'Company']]\n",
    "            df['Company'] = df['Company'].fillna(\"None\")\n",
    "            df = df.dropna(subset=['First Name', 'Last Name'])\n",
    "\n",
    "            # Save as CSV\n",
    "            new_csv_name = file.replace('.xlsx', '.csv')\n",
    "            new_csv_path = os.path.join(directory, new_csv_name)\n",
    "            df.to_csv(new_csv_path, index=False)\n",
    "\n",
    "        # Process CSV files\n",
    "        elif file.endswith('.csv'):\n",
    "            try:\n",
    "                # Try utf-8 first\n",
    "                encoding = 'utf-8'\n",
    "                header_row = find_header_row(file_path, is_excel=False, encoding=encoding)\n",
    "                df = pd.read_csv(file_path, encoding=encoding, header=header_row)\n",
    "                \n",
    "            except UnicodeDecodeError:\n",
    "                # Fallback to ISO-8859-1 if utf-8 fails\n",
    "                encoding = 'ISO-8859-1'\n",
    "                header_row = find_header_row(file_path, is_excel=False, encoding=encoding)\n",
    "                df = pd.read_csv(file_path, encoding=encoding, header=header_row)\n",
    "\n",
    "            df = df[['First Name', 'Last Name', 'Company']]\n",
    "            df['Company'] = df['Company'].fillna(\"None\")\n",
    "            df = df.dropna(subset=['First Name', 'Last Name'])\n",
    "\n",
    "            # Save cleaned data\n",
    "            df.to_csv(file_path, index=False)\n",
    "            print(\"file processed : \",file)\n",
    "        else:\n",
    "            print(file)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üóëÔ∏è Deleted 2 duplicate files:\n",
      "  - Sneha_Shaw.csv\n",
      "  - Samina_Sultana.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import hashlib\n",
    "from collections import defaultdict\n",
    "\n",
    "data_dir = r'LinkedIn Data Public'\n",
    "hash_map = defaultdict(list)\n",
    "\n",
    "def get_file_hash(filepath):\n",
    "    hasher = hashlib.md5()\n",
    "    with open(filepath, 'rb') as f:\n",
    "        buf = f.read()\n",
    "        hasher.update(buf)\n",
    "    return hasher.hexdigest()\n",
    "\n",
    "# Scan all CSVs and group by hash\n",
    "csv_files = [f for f in os.listdir(data_dir) if f.endswith('.csv')]\n",
    "for file in csv_files:\n",
    "    path = os.path.join(data_dir, file)\n",
    "    file_hash = get_file_hash(path)\n",
    "    hash_map[file_hash].append(file)\n",
    "\n",
    "# Delete duplicates, keeping one file per group\n",
    "deleted_files = []\n",
    "\n",
    "for file_list in hash_map.values():\n",
    "    if len(file_list) > 1:\n",
    "        # Keep the first file, delete the rest\n",
    "        for dup_file in file_list[1:]:\n",
    "            dup_path = os.path.join(data_dir, dup_file)\n",
    "            os.remove(dup_path)\n",
    "            deleted_files.append(dup_file)\n",
    "if len(deleted_files) == 0:\n",
    "    print(\"No duplicate files in folder\")\n",
    "    \n",
    "print(f\"üóëÔ∏è Deleted {len(deleted_files)} duplicate files:\")\n",
    "for f in deleted_files:\n",
    "    print(f\"  - {f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
